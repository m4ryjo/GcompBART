% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/GCSB.R
\name{Hypers}
\alias{Hypers}
\title{Extended Hypers for Soft BART Models}
\usage{
Hypers(
  X,
  Y,
  group = NULL,
  tgroup = NULL,
  alpha = 1,
  eta = 1,
  phi = 1,
  alpha_vec = 1,
  beta = 2,
  gamma = 0.95,
  k = 2,
  sigma_hat = NULL,
  shape = 1,
  width = 0.1,
  num_tree = 20,
  alpha_scale = NULL,
  alpha_shape_1 = 0.5,
  alpha_shape_2 = 1,
  tau_rate = 10,
  num_tree_prob = NULL,
  temperature = 1,
  weights = NULL,
  normalize_Y = TRUE
)
}
\arguments{
\item{X}{Matrix of predictors (same semantics as \code{SoftBart::Hypers}).}

\item{Y}{Response vector (same semantics as \code{SoftBart::Hypers}).}

\item{group}{Optional grouping vector for SoftBart trees.}

\item{tgroup}{Integer vector of length \code{ncol(X)} specifying time-group assignments for predictors.
If \code{NULL}, defaults to all predictors in one group.}

\item{alpha}{Positive constant controlling the sparsity level.}

\item{eta}{Numeric; GcompBART-specific prior parameter for variance shrinkage. Default = 1.}

\item{phi}{Numeric or vector; GcompBART-specific prior parameter for time-varying effect scaling. Default = 1.}

\item{alpha_vec}{Numeric or vector. Specifies ordered hyperpriors for predictor-specific
shrinkage parameters in longitudinal models. By default, all predictors share the same shrinkage level (1).
When using the longitudinal prior, \code{alpha_vec} can be set to reflect temporal ordering.}

\item{beta}{Parameter penalizing tree depth in the branching process prior.}

\item{gamma}{Parameter penalizing new nodes in the branching process prior.}

\item{k}{Related to the signal-to-noise ratio, \code{sigma_mu = 0.5 / (sqrt(num_tree) * k)}. BART defaults to \code{k = 2} after applying the max/min normalization to the outcome.}

\item{sigma_hat}{A prior guess at the conditional variance of \code{Y} given \code{X}. If not provided, this is estimated empirically by linear regression.}

\item{shape}{Shape parameter for gating probabilities.}

\item{width}{Bandwidth of gating probabilities.}

\item{num_tree}{Number of trees in the ensemble.}

\item{alpha_scale}{Scale of the prior for \code{alpha}; if not provided, defaults to the number of predictors.}

\item{alpha_shape_1}{Shape parameter for prior on \code{alpha}; if not provided, defaults to 0.5.}

\item{alpha_shape_2}{Shape parameter for prior on \code{alpha}; if not provided, defaults to 1.0.}

\item{tau_rate}{Rate parameter for the bandwidths of the trees with an exponential prior; defaults to 10.}

\item{num_tree_prob}{Parameter for geometric prior on number of tree.}

\item{temperature}{The temperature applied to the posterior distribution; set to 1 unless you know what you are doing.}

\item{weights}{Only used by the function \code{softbart}, this is a vector of weights to be used in heteroskedastic regression models, with the variance of an observation given by \code{sigma_sq / weight}.}

\item{normalize_Y}{Do you want to compute \code{sigma_hat} after applying the standard BART max/min normalization to \eqn{(-0.5, 0.5)} for the outcome? If \code{FALSE}, no normalization is applied. This might be useful for fitting custom models where the outcome is normalized by hand.}
}
\value{
A list containing all fields from \code{SoftBart::Hypers()} plus:
\itemize{
  \item \code{alpha_vec} – longitudinal alpha prior
  \item \code{eta}, \code{phi} – additional prior parameters
  \item \code{tgroup} – integer vector of predictor group assignments
  \item \code{tgroup_size} – sizes of each time group
}
}
\description{
Constructs a hyperparameter list by calling \code{SoftBart::Hypers()} for base fields
and then extends it with GcompBART-specific components: \code{alpha_vec}, \code{eta}, \code{phi},
and time-grouping information (\code{tgroup}, \code{tgroup_size}). This approach preserves
SoftBart defaults while adding longitudinal extensions.
}
\details{
For longitudinal settings, the \code{alpha_vec} parameter implements the ordered hyperprior
structure described in [Paper Citation]. This structure introduces sparsity based on
temporal proximity to the response: predictors measured earlier in time receive stronger
shrinkage (higher sparsity), while those closer to the response are penalized less, reflecting
the assumption that recent measurements are more informative.

The ordering is achieved by setting weights:
\deqn{c_j = 1 - \frac{t - j}{t - 1} \times 0.5}
where \eqn{t} is the total number of time points and \eqn{j} indexes the predictor's time point.
This results in \eqn{c_1 = 0.5} for the earliest predictors and
\eqn{0.5 < c_{j-1} < c_j < 1} for later predictors.
}
\examples{
# Example: Construct hypers for longitudinal data
X_train <- matrix(rnorm(100), ncol = 5)
Y_train <- rnorm(20)
tmp_tg <- rep(1:2, each = 10)

hypers <- Hypers(X = X_train, Y = Y_train, tgroup = tmp_tg,
                 alpha_vec = c(0.5, 0.75, 0.9, 0.95, 1),
                 eta = 1, phi = 1)

}
